{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sarit - My Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saritdi/PlantClassification/blob/main/Sarit_My_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc5dV8vVMKik"
      },
      "source": [
        "from datetime import datetime\n",
        "start_time = datetime.now()\n",
        "print(\"--- {} ---\",start_time)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmIh3NZAaEkC"
      },
      "source": [
        "# Stage 1: Install dependencies and setting up GPU environment\n",
        "!pip install tensorflow-gpu==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4PfsjfpozEA"
      },
      "source": [
        "# Importing a library that is not in Colaboratory\n",
        "!apt-get -qq install -y libfluidsynth1\n",
        "!pip install matplotlib-venn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu2mbI2Ha8UW"
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fOTP2XZimCM"
      },
      "source": [
        "# Dataset preprocessing\n",
        "# Import project dependencies\n",
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU5b6dlRwUQk"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w7lrGcW08Ds"
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "drive.mount('/content/gdrive')\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "driver = GoogleDrive(gauth)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECNPg0aZMUae"
      },
      "source": [
        "# Setting up data import for google Drive\n",
        "# Training data\n",
        "fid = driver.ListFile({'q':\"title='Train102.zip'\"}).GetList()[0]['id']\n",
        "f = driver.CreateFile({'id': fid})\n",
        "f.GetContentFile('Train102.zip')\n",
        "\n",
        "# Testing data\n",
        "fid1 = driver.ListFile({'q':\"title='Test102.zip'\"}).GetList()[0]['id']\n",
        "f1 = driver.CreateFile({'id': fid1})\n",
        "f1.GetContentFile('Test102.zip')\n",
        "\n",
        "fid2 = driver.ListFile({'q':\"title='MyHousePlants.zip'\"}).GetList()[0]['id']\n",
        "f2 = driver.CreateFile({'id': fid2})\n",
        "f2.GetContentFile('MyHousePlants.zip')\n",
        "\n",
        "# Testing data\n",
        "fid3 = driver.ListFile({'q':\"title='Test.zip'\"}).GetList()[0]['id']\n",
        "f3 = driver.CreateFile({'id': fid3})\n",
        "f3.GetContentFile('Test.zip')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZqju26HE6WK"
      },
      "source": [
        "f.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6IiWIndURMX"
      },
      "source": [
        "f1.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dz_XKWMQcaf"
      },
      "source": [
        "f2.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu6B9K_2QpY6"
      },
      "source": [
        "f3.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L1UJoysFMB-"
      },
      "source": [
        "!unzip Train102.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQHIgcmHQvHq"
      },
      "source": [
        "!unzip MyHousePlants.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_9GiNHsR95S"
      },
      "source": [
        "!unzip Test102.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWQ7gzQ1Qyda"
      },
      "source": [
        "!unzip Test.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y_yZVZuxoIR"
      },
      "source": [
        "PATH = '/content'\n",
        "os.listdir(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMvMVSYCv_k7"
      },
      "source": [
        "train_data_dir_102 = os.path.join(PATH,'Train102')\n",
        "test_data_dir_102 = os.path.join(PATH,'Test102')\n",
        "train_data_dir = os.path.join(PATH,'MyHousePlants')\n",
        "test_data_dir = os.path.join(PATH,'Test')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJcMLqD4WqKX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05094f90-bb28-4b13-cc21-936d0272c5df"
      },
      "source": [
        "print(os.listdir(test_data_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Sansevieria Ballyi', 'Parlor Palm', 'Coleus', 'House Leek', 'Paddle Plant', 'Nerve Plant', 'Zebra Cactus', 'Moon Cactus', 'Venus Fly Trap', 'String Of Banana', 'Lucky Bamboo', 'Poinsettia', \"Elephant's Ear\", 'Begonia Maculata', 'Jade Plant']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbfSB32-iZAI"
      },
      "source": [
        "# Preparing the data\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "# # Image normalization\n",
        "# Image Data Augmentation\n",
        "# # 255.0 is the highest pixel value\n",
        "image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.1,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True, \n",
        "    rotation_range = 90,\n",
        "    brightness_range = [0.5,1.0]\n",
        "    )\n",
        "\n",
        "train_data_generator_102 = image_generator.flow_from_directory(\n",
        "    directory=train_data_dir_102,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    subset=\"training\",\n",
        "    class_mode='sparse')\n",
        "\n",
        "valid_data_generator_102 = image_generator.flow_from_directory(\n",
        "    directory=train_data_dir_102,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    subset=\"validation\",\n",
        "    class_mode='sparse')\n",
        "\n",
        "test_data_generator_102 = image_generator.flow_from_directory(\n",
        "    directory=test_data_dir_102,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode = 'sparse')\n",
        "\n",
        "train_data_generator = image_generator.flow_from_directory(\n",
        "    directory=train_data_dir,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    subset=\"training\",\n",
        "    class_mode='sparse')\n",
        "\n",
        "valid_data_generator = image_generator.flow_from_directory(\n",
        "    directory=train_data_dir,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    subset=\"validation\",\n",
        "    class_mode='sparse')\n",
        "\n",
        "test_data_generator = image_generator.flow_from_directory(\n",
        "    directory=test_data_dir,\n",
        "    shuffle=True,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    class_mode = 'sparse')\n",
        "\n",
        "class_names = list(train_data_generator.class_indices.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-LA-fwHH17B"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 3 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "sample_training_images, _ = next(train_data_generator_102)\n",
        "plotImages(sample_training_images[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owkKMJiFmZhj"
      },
      "source": [
        "# Loading the pre-trained model (MobileNetV2)\n",
        "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "base_model = tf.keras.applications.DenseNet201(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFlhPT4-oMxL"
      },
      "source": [
        "# Freezing the base model\n",
        "# base_model.shape=(None, 4, 4, 1280) - too big\n",
        "base_model.trainable = False\n",
        "print(base_model.output)\n",
        "# takes the whole input instead of taking parts at a time\n",
        "# takes an average of numbers in an input = output of the base_model\n",
        "# convert features to vectors\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "print(global_average_layer)\n",
        "prediction_layer = tf.keras.layers.Dense(units=102, activation='softmax')(global_average_layer)\n",
        "print(prediction_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUHmyw4CqLTz"
      },
      "source": [
        "# Defining the model\n",
        "# Combining two models\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=prediction_layer)\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), loss=\"sparse_categorical_crossentropy\", metrics=[\"SparseCategoricalAccuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuDFGTyxVM9k"
      },
      "source": [
        "train = train_data_generator_102\n",
        "valid = valid_data_generator_102\n",
        "epochs = 50\n",
        "history = model.fit(train,  \n",
        "                    epochs = epochs, \n",
        "                    validation_data=valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNq_b-dQYKfZ"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "acc = history.history['sparse_categorical_accuracy']\n",
        "val_acc = history.history['val_sparse_categorical_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bsc0GzhCxNrz"
      },
      "source": [
        "valid_loss, valid_accuracy = model.evaluate(valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XOGP0tExZvv"
      },
      "source": [
        "print(\"Accuracy after transfer learnןing: {}\".format(valid_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbl-jlRMU0Nh"
      },
      "source": [
        "test_accu = model.evaluate(test_data_generator_102)\n",
        "print('The testing accuracy is :',test_accu[1]*100, '%')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9CHIFobyTVe"
      },
      "source": [
        "base_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgijBsNS04AN"
      },
      "source": [
        "#fine_tune_at = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8hnc35D1EOc"
      },
      "source": [
        "# for layer in base_model.layers[:fine_tune_at]:\n",
        "#     layer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOM615rt1POD"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['SparseCategoricalAccuracy'])\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPRnLqEu2G5z"
      },
      "source": [
        "\n",
        "train = train_data_generator\n",
        "valid = valid_data_generator\n",
        "epochs = 30\n",
        "history = model.fit(train,  \n",
        "                    epochs = epochs, \n",
        "                    validation_data=valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPTyisdx33u3"
      },
      "source": [
        "valid_loss, valid_accuracy = model.evaluate(valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jijEA5n26yQu"
      },
      "source": [
        "print(\"Validation accuracy after fine tuning: {}\".format(valid_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNnjh1vQIagW"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "acc = history.history['sparse_categorical_accuracy']\n",
        "val_acc = history.history['val_sparse_categorical_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uxi2WbD8VgJF"
      },
      "source": [
        "test_accu = model.evaluate(test_data_generator)\n",
        "print('The testing accuracy is :',test_accu[1]*100, '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AJJ8hMHM4j5"
      },
      "source": [
        "end_time = datetime.now()\n",
        "print(\"--- {} ---\",end_time)\n",
        "print(\"-----total time {}-----\",end_time-start_time)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SXdk9z5Nia9"
      },
      "source": [
        "### Yet to be implemented\n",
        "\n",
        "# Save my model\n",
        "# Fetch the Keras session and save the model\n",
        "# The signature definition is defined by the input and output tensors,\n",
        "# and stored with the default serving key\n",
        "import tempfile\n",
        "\n",
        "MODEL_DIR = tempfile.gettempdir()\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "print('export_path = {}\\n'.format(export_path))\n",
        "\n",
        "tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        ")\n",
        "\n",
        "print('\\nSaved model:')\n",
        "!ls -l {export_path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9isWeMUN-r8"
      },
      "source": [
        "# Examine your saved model\n",
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWg9X2QHlbGS"
      },
      "source": [
        "# Serve your model with TensorFlow Serving\n",
        "\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygwa9AgRloYy"
      },
      "source": [
        "# Install TensorFlow Serving\n",
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5NrYdQeVm52"
      },
      "source": [
        "### Start running TensorFlow Serving\n",
        "\n",
        "This is where we start running TensorFlow Serving and load our model.  After it loads we can start making inference requests using REST.  There are some important parameters:\n",
        "\n",
        "* `rest_api_port`: The port that you'll use for REST requests.\n",
        "* `model_name`: You'll use this in the URL of REST requests.  It can be anything.\n",
        "* `model_base_path`: This is the path to the directory where you've saved your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUgp3vUdU5GS"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJDhHNJVnaLN"
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=PlantIL_model \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxbeiOCUUs2z"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwg1JKaGXWAg"
      },
      "source": [
        "## Make a request to your model in TensorFlow Serving\n",
        "\n",
        "This part of the code is still not implemented\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Luqm_Jyff9iR"
      },
      "source": [
        "test = test_data_generator\n",
        "test_images, test_labels  = next(test)\n",
        "test_labels = [int(i) for i in list(test_labels)]\n",
        "class_names = list(test_data_generator.class_indices.keys())\n",
        "print(class_names)\n",
        "\n",
        "def show(idx, title):\n",
        "  plt.figure()\n",
        "  plt.imshow(test_images[idx])\n",
        "  plt.axis('off')\n",
        "  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n",
        "\n",
        "import random\n",
        "rando = random.randint(0,len(test_images)-1)\n",
        "show(rando, 'An Example Image: {}'.format(class_names[test_labels[rando]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dsD7KQG1m-R"
      },
      "source": [
        "import json\n",
        "test = test_data_generator\n",
        "test_images, test_labels  = next(test)\n",
        "test_labels = [int(i) for i in list(test_labels)]\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test_images[0:10].tolist()})\n",
        "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))\n",
        "\n",
        "!pip install -q requests\n",
        "\n",
        "import requests\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8501/v1/models/PlantIL_model:predict', data=data, headers=headers)\n",
        "predictions = json.loads(json_response.text)['predictions']\n",
        "print(predictions[0])\n",
        "print(np.argmax(predictions[0]))\n",
        "\n",
        "show(0, 'The model thought this was a {} (class {}), and it was actually a {} (class {})'.format(\n",
        "  class_names[np.argmax(predictions[0])], np.argmax(predictions[0]), class_names[test_labels[0]], test_labels[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QztlxfqLi2jP"
      },
      "source": [
        "model.save('/content/UrbanPlantClassifier.h5')\n",
        "model.save('/content/gdrive/MyDrive/UrbanPlantClassifier.h5')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zuVNd15nKm5"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/gdrive/MyDrive/DenseNet201-4.h5')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKdGgAFbn1J7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}